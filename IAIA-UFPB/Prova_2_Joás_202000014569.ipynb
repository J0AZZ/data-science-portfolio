{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prova 2_Joás_202000014569.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7k_CAfcUKHjG",
        "sS8D2olfEhxq",
        "-buFRUL8EWJ_",
        "-iulntNQjzPQ",
        "_w3ge5hetaYc"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK4tvZIyJ2eP"
      },
      "source": [
        "# Introdução à Inteligência Artificial\n",
        "## Prova 2\n",
        "### Joás de Brito Ferreira Filho \n",
        "\n",
        "Curso: `Estatística`\n",
        "\n",
        "Matrícula: `202000014569`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JaLsph-Eb7W"
      },
      "source": [
        "### Requisições do Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN7WDvd5OXwC"
      },
      "source": [
        "# dataframe manipulation\n",
        "import pandas as pd\n",
        "\n",
        "# visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# vector operations\n",
        "import numpy as np\n",
        "\n",
        "# data preprocessing and model building\n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, ElasticNet\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k_CAfcUKHjG"
      },
      "source": [
        "# Questão `I`\n",
        "https://www.kaggle.com/c/titanic/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS8D2olfEhxq"
      },
      "source": [
        "### Aquisição e Análise Exploratória dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCSIjiA7B6ll"
      },
      "source": [
        "train_index = \"https://raw.githubusercontent.com/J0AZZ/artificial-intelligence_studies/master/IAIA-UFPB/Prova%202/train1.csv\"\n",
        "Train = pd.read_csv(train_index)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VMSyStYLFV4e",
        "outputId": "44b543ce-9d67-427d-eefb-f4e9af91aedb"
      },
      "source": [
        "# SAMPLE\n",
        "Train.head()\n",
        "# Test.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WR8FcTwgFye3",
        "outputId": "28b5530c-54af-455d-d9fa-cb7ae14daa65"
      },
      "source": [
        "# NUMERICAL DATA\n",
        "numerical_labels = Train.describe().columns\n",
        "\n",
        "# SUMMARY STATISTICS\n",
        "Train.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>714.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.383838</td>\n",
              "      <td>2.308642</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>32.204208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>257.353842</td>\n",
              "      <td>0.486592</td>\n",
              "      <td>0.836071</td>\n",
              "      <td>14.526497</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "      <td>49.693429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>223.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.910400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>668.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId    Survived      Pclass  ...       SibSp       Parch        Fare\n",
              "count   891.000000  891.000000  891.000000  ...  891.000000  891.000000  891.000000\n",
              "mean    446.000000    0.383838    2.308642  ...    0.523008    0.381594   32.204208\n",
              "std     257.353842    0.486592    0.836071  ...    1.102743    0.806057   49.693429\n",
              "min       1.000000    0.000000    1.000000  ...    0.000000    0.000000    0.000000\n",
              "25%     223.500000    0.000000    2.000000  ...    0.000000    0.000000    7.910400\n",
              "50%     446.000000    0.000000    3.000000  ...    0.000000    0.000000   14.454200\n",
              "75%     668.500000    1.000000    3.000000  ...    1.000000    0.000000   31.000000\n",
              "max     891.000000    1.000000    3.000000  ...    8.000000    6.000000  512.329200\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZrtqppKAr3Jb",
        "outputId": "f6d1cbe9-b0e0-4c18-b6a1-dc920c0517bc"
      },
      "source": [
        "# correlation analysis\n",
        "Train.corr()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PassengerId</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.005007</td>\n",
              "      <td>-0.035144</td>\n",
              "      <td>0.036847</td>\n",
              "      <td>-0.057527</td>\n",
              "      <td>-0.001652</td>\n",
              "      <td>0.012658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Survived</th>\n",
              "      <td>-0.005007</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.338481</td>\n",
              "      <td>-0.077221</td>\n",
              "      <td>-0.035322</td>\n",
              "      <td>0.081629</td>\n",
              "      <td>0.257307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pclass</th>\n",
              "      <td>-0.035144</td>\n",
              "      <td>-0.338481</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.369226</td>\n",
              "      <td>0.083081</td>\n",
              "      <td>0.018443</td>\n",
              "      <td>-0.549500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0.036847</td>\n",
              "      <td>-0.077221</td>\n",
              "      <td>-0.369226</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.308247</td>\n",
              "      <td>-0.189119</td>\n",
              "      <td>0.096067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SibSp</th>\n",
              "      <td>-0.057527</td>\n",
              "      <td>-0.035322</td>\n",
              "      <td>0.083081</td>\n",
              "      <td>-0.308247</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.414838</td>\n",
              "      <td>0.159651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Parch</th>\n",
              "      <td>-0.001652</td>\n",
              "      <td>0.081629</td>\n",
              "      <td>0.018443</td>\n",
              "      <td>-0.189119</td>\n",
              "      <td>0.414838</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.216225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fare</th>\n",
              "      <td>0.012658</td>\n",
              "      <td>0.257307</td>\n",
              "      <td>-0.549500</td>\n",
              "      <td>0.096067</td>\n",
              "      <td>0.159651</td>\n",
              "      <td>0.216225</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             PassengerId  Survived    Pclass  ...     SibSp     Parch      Fare\n",
              "PassengerId     1.000000 -0.005007 -0.035144  ... -0.057527 -0.001652  0.012658\n",
              "Survived       -0.005007  1.000000 -0.338481  ... -0.035322  0.081629  0.257307\n",
              "Pclass         -0.035144 -0.338481  1.000000  ...  0.083081  0.018443 -0.549500\n",
              "Age             0.036847 -0.077221 -0.369226  ... -0.308247 -0.189119  0.096067\n",
              "SibSp          -0.057527 -0.035322  0.083081  ...  1.000000  0.414838  0.159651\n",
              "Parch          -0.001652  0.081629  0.018443  ...  0.414838  1.000000  0.216225\n",
              "Fare            0.012658  0.257307 -0.549500  ...  0.159651  0.216225  1.000000\n",
              "\n",
              "[7 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT7ZqfKoF4gE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab39b5f4-6fc1-4d45-fa00-50851a351cfc"
      },
      "source": [
        "# DATA TYPES\n",
        "Train.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lerKq_GxOP3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9b1c8a19-2863-4283-f090-b29e1f6c5714"
      },
      "source": [
        "plt.hist(Train[\"Survived\"])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([549.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 342.]),\n",
              " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-buFRUL8EWJ_"
      },
      "source": [
        "### Pré-processamento dos Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPNi-Z2EnGv5"
      },
      "source": [
        "Nesta seção procederemos com o tratamento dos dados. Por tratar-se de uma competição do Kaggle, utilizaremos apenas os dados que possam ser validados por uma função de erro do modelo; isto é, utilizaremos apenas amostras que contenham a variável `Survived`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7S3-rUYDi2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f17a186-642a-44e7-de60-d14a6f513c7e"
      },
      "source": [
        "# DATA NORMALIZATION\n",
        "\n",
        "# set categorical to numerical attributes\n",
        "categorical = Train.copy().drop(numerical_labels, axis=1).drop([\"Name\", \"Ticket\"], axis=1)\n",
        "dummies = pd.get_dummies(categorical)\n",
        "\n",
        "# drop samples with NaN values\n",
        "dataset = pd.concat([dummies, Train[numerical_labels]], axis=1).dropna()\n",
        "X = dataset.copy().drop(\"Survived\", axis=1)\n",
        "y = dataset[\"Survived\"]\n",
        "\n",
        "# standardize data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit(X).transform(X)\n",
        "\n",
        "# get 10 folds indexes\n",
        "skf = StratifiedKFold(n_splits=10)\n",
        "skf.get_n_splits(X, y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_--BDBezC4x"
      },
      "source": [
        "### Construção e Avaliação dos Modelos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkSiYrOD3uW5",
        "outputId": "caa76922-1370-49bc-884a-98219e9d249e"
      },
      "source": [
        "# different parameters combinations\n",
        "parameters = [['l1', 'l2'], [True, False], ['best', 'random'], ['gini', 'entropy']]\n",
        "\n",
        "for train_index, test_index in skf.split(X_scaled, y):\n",
        "  # current K-Fold sets\n",
        "  X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "  for i in range(2):\n",
        "    for j in range(2):\n",
        "      # Logistic Regression\n",
        "      logreg = LogisticRegression(solver='liblinear',max_iter=9999, random_state=17, penalty=parameters[0][i])\n",
        "      logreg.fit(X_train, y_train)\n",
        "      logreg_preds = logreg.predict(X_test)\n",
        "      print(\"---------------------------------------------\")\n",
        "      print(\"Logistic Regression\\n[+] Parameters:\")\n",
        "      print(\"penalty=\",parameters[0][i]) # l1 or l2 penalty\n",
        "      print(\"fit_intercept=\",parameters[1][i]) # bias existence\n",
        "      print(\"\\n[+] Metrics:\")\n",
        "      print(\"Accuracy: \", sk.metrics.accuracy_score(y_test, logreg_preds) *100, \" %\")\n",
        "      print(\"Average Precision Score: \", sk.metrics.average_precision_score(y_test, logreg_preds))\n",
        "      \n",
        "      # Decision Tree\n",
        "      dectree = DecisionTreeClassifier(random_state=17, splitter=parameters[2][j])\n",
        "      dectree.fit(X_train, y_train)\n",
        "      dectree_preds = dectree.predict(X_test)\n",
        "      print(\"\\n\\nDecision Tree\\n[+] Parameters:\")\n",
        "      print(\"splitter=\",parameters[2][j]) # best split or random best split\n",
        "      print(\"criterion=\",parameters[3][j]) # gini or entropy criterion\n",
        "      print(\"\\n[+] Metrics:\")\n",
        "      print(\"Accuracy: \", sk.metrics.accuracy_score(y_test, logreg_preds) *100, \" %\")\n",
        "      print(\"Average Precision Score: \", sk.metrics.average_precision_score(y_test, dectree_preds), \"\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  76.38888888888889  %\n",
            "Average Precision Score:  0.6176108374384237\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  76.38888888888889  %\n",
            "Average Precision Score:  0.47867816091954024 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  76.38888888888889  %\n",
            "Average Precision Score:  0.6176108374384237\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  76.38888888888889  %\n",
            "Average Precision Score:  0.5863266283524905 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  76.38888888888889  %\n",
            "Average Precision Score:  0.6176687297376953\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  76.38888888888889  %\n",
            "Average Precision Score:  0.47867816091954024 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  76.38888888888889  %\n",
            "Average Precision Score:  0.6176687297376953\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  76.38888888888889  %\n",
            "Average Precision Score:  0.5863266283524905 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  75.0  %\n",
            "Average Precision Score:  0.5999361430395913\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  75.0  %\n",
            "Average Precision Score:  0.5818965517241379 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  75.0  %\n",
            "Average Precision Score:  0.5999361430395913\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  75.0  %\n",
            "Average Precision Score:  0.4899425287356322 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  75.0  %\n",
            "Average Precision Score:  0.5999361430395913\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  75.0  %\n",
            "Average Precision Score:  0.5818965517241379 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  75.0  %\n",
            "Average Precision Score:  0.5999361430395913\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  75.0  %\n",
            "Average Precision Score:  0.4899425287356322 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  79.16666666666666  %\n",
            "Average Precision Score:  0.6649425287356321\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  79.16666666666666  %\n",
            "Average Precision Score:  0.6176687297376953 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  79.16666666666666  %\n",
            "Average Precision Score:  0.6649425287356321\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  79.16666666666666  %\n",
            "Average Precision Score:  0.48813496477567664 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  79.16666666666666  %\n",
            "Average Precision Score:  0.6649425287356321\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  79.16666666666666  %\n",
            "Average Precision Score:  0.6176687297376953 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  79.16666666666666  %\n",
            "Average Precision Score:  0.6649425287356321\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  79.16666666666666  %\n",
            "Average Precision Score:  0.48813496477567664 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  86.11111111111111  %\n",
            "Average Precision Score:  0.7507724632307502\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  86.11111111111111  %\n",
            "Average Precision Score:  0.5272988505747126 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  86.11111111111111  %\n",
            "Average Precision Score:  0.7507724632307502\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  86.11111111111111  %\n",
            "Average Precision Score:  0.5208551027516545 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  87.5  %\n",
            "Average Precision Score:  0.7739463601532567\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  87.5  %\n",
            "Average Precision Score:  0.5272988505747126 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  87.5  %\n",
            "Average Precision Score:  0.7739463601532567\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  87.5  %\n",
            "Average Precision Score:  0.5208551027516545 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  71.83098591549296  %\n",
            "Average Precision Score:  0.5716993842924063\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  71.83098591549296  %\n",
            "Average Precision Score:  0.6387761049052938 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  71.83098591549296  %\n",
            "Average Precision Score:  0.5716993842924063\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  71.83098591549296  %\n",
            "Average Precision Score:  0.6758944471426258 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  70.4225352112676  %\n",
            "Average Precision Score:  0.5557875991581673\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  70.4225352112676  %\n",
            "Average Precision Score:  0.6387761049052938 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  70.4225352112676  %\n",
            "Average Precision Score:  0.5557875991581673\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  70.4225352112676  %\n",
            "Average Precision Score:  0.6758944471426258 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  78.87323943661971  %\n",
            "Average Precision Score:  0.6557795046138902\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  78.87323943661971  %\n",
            "Average Precision Score:  0.5377930012014008 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  78.87323943661971  %\n",
            "Average Precision Score:  0.6557795046138902\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  78.87323943661971  %\n",
            "Average Precision Score:  0.5461499403947194 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  80.28169014084507  %\n",
            "Average Precision Score:  0.674096900068664\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  80.28169014084507  %\n",
            "Average Precision Score:  0.5377930012014008 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  80.28169014084507  %\n",
            "Average Precision Score:  0.674096900068664\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  80.28169014084507  %\n",
            "Average Precision Score:  0.5461499403947194 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  78.87323943661971  %\n",
            "Average Precision Score:  0.6627665680604001\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  78.87323943661971  %\n",
            "Average Precision Score:  0.70667579142567 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  78.87323943661971  %\n",
            "Average Precision Score:  0.6627665680604001\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  78.87323943661971  %\n",
            "Average Precision Score:  0.6672899465760077 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  77.46478873239437  %\n",
            "Average Precision Score:  0.6406866989040692\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  77.46478873239437  %\n",
            "Average Precision Score:  0.70667579142567 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  77.46478873239437  %\n",
            "Average Precision Score:  0.6406866989040692\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  77.46478873239437  %\n",
            "Average Precision Score:  0.6672899465760077 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  77.46478873239437  %\n",
            "Average Precision Score:  0.6435625245727237\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  77.46478873239437  %\n",
            "Average Precision Score:  0.6925530192650154 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  77.46478873239437  %\n",
            "Average Precision Score:  0.6435625245727237\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  77.46478873239437  %\n",
            "Average Precision Score:  0.6219921409333745 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  78.87323943661971  %\n",
            "Average Precision Score:  0.6672899465760077\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  78.87323943661971  %\n",
            "Average Precision Score:  0.6925530192650154 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  78.87323943661971  %\n",
            "Average Precision Score:  0.6672899465760077\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  78.87323943661971  %\n",
            "Average Precision Score:  0.6219921409333745 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  81.69014084507043  %\n",
            "Average Precision Score:  0.6911121903836814\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  81.69014084507043  %\n",
            "Average Precision Score:  0.7278518984087078 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  81.69014084507043  %\n",
            "Average Precision Score:  0.6911121903836814\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  81.69014084507043  %\n",
            "Average Precision Score:  0.6975566929428026 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  81.69014084507043  %\n",
            "Average Precision Score:  0.6911121903836814\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  81.69014084507043  %\n",
            "Average Precision Score:  0.7278518984087078 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  81.69014084507043  %\n",
            "Average Precision Score:  0.6911121903836814\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  81.69014084507043  %\n",
            "Average Precision Score:  0.6975566929428026 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  80.28169014084507  %\n",
            "Average Precision Score:  0.674096900068664\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  80.28169014084507  %\n",
            "Average Precision Score:  0.6975566929428026 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l1\n",
            "fit_intercept= True\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  80.28169014084507  %\n",
            "Average Precision Score:  0.674096900068664\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  80.28169014084507  %\n",
            "Average Precision Score:  0.7209519184069936 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  80.28169014084507  %\n",
            "Average Precision Score:  0.674096900068664\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= best\n",
            "criterion= gini\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  80.28169014084507  %\n",
            "Average Precision Score:  0.6975566929428026 \n",
            "---------------------------------------------\n",
            "Logistic Regression\n",
            "[+] Parameters:\n",
            "penalty= l2\n",
            "fit_intercept= False\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  80.28169014084507  %\n",
            "Average Precision Score:  0.674096900068664\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "[+] Parameters:\n",
            "splitter= random\n",
            "criterion= entropy\n",
            "\n",
            "[+] Metrics:\n",
            "Accuracy:  80.28169014084507  %\n",
            "Average Precision Score:  0.7209519184069936 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL40bvZKiwD2"
      },
      "source": [
        "Como mostram os resultados, o modelo que obteve melhores métricas foi o de Árvore de Decisão, com parâmetros `splitter='random'` e `criterion='entropy'`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QufC7idNKYl-"
      },
      "source": [
        "# Questão `II`\n",
        "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iulntNQjzPQ"
      },
      "source": [
        "### Aquisição e Análise Exploratória dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZvvScT3jz_n"
      },
      "source": [
        "Train = pd.read_csv(\"https://raw.githubusercontent.com/J0AZZ/artificial-intelligence_studies/master/IAIA-UFPB/Prova%202/train2.csv\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0bgohqE4qEOK",
        "outputId": "b8b965ee-2af7-4a90-93d6-d832ccd5fc35"
      },
      "source": [
        "Train.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>...</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>196.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>706</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>978</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>486</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>655</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  ...  SaleType  SaleCondition SalePrice\n",
              "0   1          60       RL  ...        WD         Normal    208500\n",
              "1   2          20       RL  ...        WD         Normal    181500\n",
              "2   3          60       RL  ...        WD         Normal    223500\n",
              "3   4          70       RL  ...        WD        Abnorml    140000\n",
              "4   5          60       RL  ...        WD         Normal    250000\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2IqfZxVuqGcf",
        "outputId": "2eb6cca6-d868-4a5c-bda6-d5be6097cdca"
      },
      "source": [
        "numerical_labels = Train.describe().columns\n",
        "Train.describe()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1201.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1452.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1379.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>730.500000</td>\n",
              "      <td>56.897260</td>\n",
              "      <td>70.049958</td>\n",
              "      <td>10516.828082</td>\n",
              "      <td>6.099315</td>\n",
              "      <td>5.575342</td>\n",
              "      <td>1971.267808</td>\n",
              "      <td>1984.865753</td>\n",
              "      <td>103.685262</td>\n",
              "      <td>443.639726</td>\n",
              "      <td>46.549315</td>\n",
              "      <td>567.240411</td>\n",
              "      <td>1057.429452</td>\n",
              "      <td>1162.626712</td>\n",
              "      <td>346.992466</td>\n",
              "      <td>5.844521</td>\n",
              "      <td>1515.463699</td>\n",
              "      <td>0.425342</td>\n",
              "      <td>0.057534</td>\n",
              "      <td>1.565068</td>\n",
              "      <td>0.382877</td>\n",
              "      <td>2.866438</td>\n",
              "      <td>1.046575</td>\n",
              "      <td>6.517808</td>\n",
              "      <td>0.613014</td>\n",
              "      <td>1978.506164</td>\n",
              "      <td>1.767123</td>\n",
              "      <td>472.980137</td>\n",
              "      <td>94.244521</td>\n",
              "      <td>46.660274</td>\n",
              "      <td>21.954110</td>\n",
              "      <td>3.409589</td>\n",
              "      <td>15.060959</td>\n",
              "      <td>2.758904</td>\n",
              "      <td>43.489041</td>\n",
              "      <td>6.321918</td>\n",
              "      <td>2007.815753</td>\n",
              "      <td>180921.195890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>421.610009</td>\n",
              "      <td>42.300571</td>\n",
              "      <td>24.284752</td>\n",
              "      <td>9981.264932</td>\n",
              "      <td>1.382997</td>\n",
              "      <td>1.112799</td>\n",
              "      <td>30.202904</td>\n",
              "      <td>20.645407</td>\n",
              "      <td>181.066207</td>\n",
              "      <td>456.098091</td>\n",
              "      <td>161.319273</td>\n",
              "      <td>441.866955</td>\n",
              "      <td>438.705324</td>\n",
              "      <td>386.587738</td>\n",
              "      <td>436.528436</td>\n",
              "      <td>48.623081</td>\n",
              "      <td>525.480383</td>\n",
              "      <td>0.518911</td>\n",
              "      <td>0.238753</td>\n",
              "      <td>0.550916</td>\n",
              "      <td>0.502885</td>\n",
              "      <td>0.815778</td>\n",
              "      <td>0.220338</td>\n",
              "      <td>1.625393</td>\n",
              "      <td>0.644666</td>\n",
              "      <td>24.689725</td>\n",
              "      <td>0.747315</td>\n",
              "      <td>213.804841</td>\n",
              "      <td>125.338794</td>\n",
              "      <td>66.256028</td>\n",
              "      <td>61.119149</td>\n",
              "      <td>29.317331</td>\n",
              "      <td>55.757415</td>\n",
              "      <td>40.177307</td>\n",
              "      <td>496.123024</td>\n",
              "      <td>2.703626</td>\n",
              "      <td>1.328095</td>\n",
              "      <td>79442.502883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1872.000000</td>\n",
              "      <td>1950.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>334.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>334.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1900.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2006.000000</td>\n",
              "      <td>34900.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>365.750000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>7553.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1954.000000</td>\n",
              "      <td>1967.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>795.750000</td>\n",
              "      <td>882.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1129.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1961.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>334.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2007.000000</td>\n",
              "      <td>129975.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>730.500000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>9478.500000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1973.000000</td>\n",
              "      <td>1994.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>383.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>477.500000</td>\n",
              "      <td>991.500000</td>\n",
              "      <td>1087.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1464.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1980.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2008.000000</td>\n",
              "      <td>163000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1095.250000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>11601.500000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2004.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>712.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>1298.250000</td>\n",
              "      <td>1391.250000</td>\n",
              "      <td>728.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1776.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2002.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>576.000000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2009.000000</td>\n",
              "      <td>214000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>313.000000</td>\n",
              "      <td>215245.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>1600.000000</td>\n",
              "      <td>5644.000000</td>\n",
              "      <td>1474.000000</td>\n",
              "      <td>2336.000000</td>\n",
              "      <td>6110.000000</td>\n",
              "      <td>4692.000000</td>\n",
              "      <td>2065.000000</td>\n",
              "      <td>572.000000</td>\n",
              "      <td>5642.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1418.000000</td>\n",
              "      <td>857.000000</td>\n",
              "      <td>547.000000</td>\n",
              "      <td>552.000000</td>\n",
              "      <td>508.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>738.000000</td>\n",
              "      <td>15500.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>755000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Id   MSSubClass  ...       YrSold      SalePrice\n",
              "count  1460.000000  1460.000000  ...  1460.000000    1460.000000\n",
              "mean    730.500000    56.897260  ...  2007.815753  180921.195890\n",
              "std     421.610009    42.300571  ...     1.328095   79442.502883\n",
              "min       1.000000    20.000000  ...  2006.000000   34900.000000\n",
              "25%     365.750000    20.000000  ...  2007.000000  129975.000000\n",
              "50%     730.500000    50.000000  ...  2008.000000  163000.000000\n",
              "75%    1095.250000    70.000000  ...  2009.000000  214000.000000\n",
              "max    1460.000000   190.000000  ...  2010.000000  755000.000000\n",
              "\n",
              "[8 rows x 38 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztdb2id1q7XD",
        "outputId": "054d0d79-ebae-4260-d138-cd9b478f02f5"
      },
      "source": [
        "Train.info()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 81 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             1460 non-null   int64  \n",
            " 1   MSSubClass     1460 non-null   int64  \n",
            " 2   MSZoning       1460 non-null   object \n",
            " 3   LotFrontage    1201 non-null   float64\n",
            " 4   LotArea        1460 non-null   int64  \n",
            " 5   Street         1460 non-null   object \n",
            " 6   Alley          91 non-null     object \n",
            " 7   LotShape       1460 non-null   object \n",
            " 8   LandContour    1460 non-null   object \n",
            " 9   Utilities      1460 non-null   object \n",
            " 10  LotConfig      1460 non-null   object \n",
            " 11  LandSlope      1460 non-null   object \n",
            " 12  Neighborhood   1460 non-null   object \n",
            " 13  Condition1     1460 non-null   object \n",
            " 14  Condition2     1460 non-null   object \n",
            " 15  BldgType       1460 non-null   object \n",
            " 16  HouseStyle     1460 non-null   object \n",
            " 17  OverallQual    1460 non-null   int64  \n",
            " 18  OverallCond    1460 non-null   int64  \n",
            " 19  YearBuilt      1460 non-null   int64  \n",
            " 20  YearRemodAdd   1460 non-null   int64  \n",
            " 21  RoofStyle      1460 non-null   object \n",
            " 22  RoofMatl       1460 non-null   object \n",
            " 23  Exterior1st    1460 non-null   object \n",
            " 24  Exterior2nd    1460 non-null   object \n",
            " 25  MasVnrType     1452 non-null   object \n",
            " 26  MasVnrArea     1452 non-null   float64\n",
            " 27  ExterQual      1460 non-null   object \n",
            " 28  ExterCond      1460 non-null   object \n",
            " 29  Foundation     1460 non-null   object \n",
            " 30  BsmtQual       1423 non-null   object \n",
            " 31  BsmtCond       1423 non-null   object \n",
            " 32  BsmtExposure   1422 non-null   object \n",
            " 33  BsmtFinType1   1423 non-null   object \n",
            " 34  BsmtFinSF1     1460 non-null   int64  \n",
            " 35  BsmtFinType2   1422 non-null   object \n",
            " 36  BsmtFinSF2     1460 non-null   int64  \n",
            " 37  BsmtUnfSF      1460 non-null   int64  \n",
            " 38  TotalBsmtSF    1460 non-null   int64  \n",
            " 39  Heating        1460 non-null   object \n",
            " 40  HeatingQC      1460 non-null   object \n",
            " 41  CentralAir     1460 non-null   object \n",
            " 42  Electrical     1459 non-null   object \n",
            " 43  1stFlrSF       1460 non-null   int64  \n",
            " 44  2ndFlrSF       1460 non-null   int64  \n",
            " 45  LowQualFinSF   1460 non-null   int64  \n",
            " 46  GrLivArea      1460 non-null   int64  \n",
            " 47  BsmtFullBath   1460 non-null   int64  \n",
            " 48  BsmtHalfBath   1460 non-null   int64  \n",
            " 49  FullBath       1460 non-null   int64  \n",
            " 50  HalfBath       1460 non-null   int64  \n",
            " 51  BedroomAbvGr   1460 non-null   int64  \n",
            " 52  KitchenAbvGr   1460 non-null   int64  \n",
            " 53  KitchenQual    1460 non-null   object \n",
            " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
            " 55  Functional     1460 non-null   object \n",
            " 56  Fireplaces     1460 non-null   int64  \n",
            " 57  FireplaceQu    770 non-null    object \n",
            " 58  GarageType     1379 non-null   object \n",
            " 59  GarageYrBlt    1379 non-null   float64\n",
            " 60  GarageFinish   1379 non-null   object \n",
            " 61  GarageCars     1460 non-null   int64  \n",
            " 62  GarageArea     1460 non-null   int64  \n",
            " 63  GarageQual     1379 non-null   object \n",
            " 64  GarageCond     1379 non-null   object \n",
            " 65  PavedDrive     1460 non-null   object \n",
            " 66  WoodDeckSF     1460 non-null   int64  \n",
            " 67  OpenPorchSF    1460 non-null   int64  \n",
            " 68  EnclosedPorch  1460 non-null   int64  \n",
            " 69  3SsnPorch      1460 non-null   int64  \n",
            " 70  ScreenPorch    1460 non-null   int64  \n",
            " 71  PoolArea       1460 non-null   int64  \n",
            " 72  PoolQC         7 non-null      object \n",
            " 73  Fence          281 non-null    object \n",
            " 74  MiscFeature    54 non-null     object \n",
            " 75  MiscVal        1460 non-null   int64  \n",
            " 76  MoSold         1460 non-null   int64  \n",
            " 77  YrSold         1460 non-null   int64  \n",
            " 78  SaleType       1460 non-null   object \n",
            " 79  SaleCondition  1460 non-null   object \n",
            " 80  SalePrice      1460 non-null   int64  \n",
            "dtypes: float64(3), int64(35), object(43)\n",
            "memory usage: 924.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xW8XZHfwrnQ-",
        "outputId": "4b752587-26e8-426a-b5e2-fd877c6ce7b7"
      },
      "source": [
        "# correlation analysis\n",
        "correlation = Train.corr()[\"SalePrice\"]\n",
        "\n",
        "# get relevant features\n",
        "relevant_corr = correlation[abs(correlation) > 0.5]\n",
        "relevant = relevant_corr.keys()\n",
        "print(relevant_corr) # these are the relevant labels\n",
        "\n",
        "# target histogram\n",
        "Train[\"SalePrice\"].hist(bins=75)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OverallQual     0.790982\n",
            "YearBuilt       0.522897\n",
            "YearRemodAdd    0.507101\n",
            "TotalBsmtSF     0.613581\n",
            "1stFlrSF        0.605852\n",
            "GrLivArea       0.708624\n",
            "FullBath        0.560664\n",
            "TotRmsAbvGrd    0.533723\n",
            "GarageCars      0.640409\n",
            "GarageArea      0.623431\n",
            "SalePrice       1.000000\n",
            "Name: SalePrice, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f08fe554750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w3ge5hetaYc"
      },
      "source": [
        "### Pré-processamento dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s4Z4z-ptY6J",
        "outputId": "dd8d97a6-0700-4806-89dc-1c428dac034a"
      },
      "source": [
        "# we already have the numerical features\n",
        "numerical = Train[relevant]\n",
        "\n",
        "# take only the most relevant categorical features\n",
        "Categorical = Train.copy().drop(numerical_labels, axis=1)\n",
        "categorical = Categorical[[\"MSZoning\", \"LandSlope\", \"Condition1\", \"Condition2\", \"ExterQual\", \"ExterCond\"]]\n",
        "\n",
        "# categorical to numerical representation\n",
        "dummies = pd.get_dummies(categorical)\n",
        "\n",
        "# standardize features \n",
        "dataset = pd.concat([numerical, dummies], axis=1)\n",
        "dataset.drop(dataset.isna().index, axis=0)\n",
        "# split target and attributes\n",
        "X = dataset.copy().drop(\"SalePrice\", axis=1)\n",
        "y = dataset[\"SalePrice\"].copy().fillna(value=163000) # fill NaN prices with the median\n",
        "# standardization\n",
        "X_scaled = sk.preprocessing.normalize(scaler.fit(X).transform(X), axis=0)\n",
        "y_scaled = scaler.fit(np.array(y).reshape(-1,1)).transform(np.array(y).reshape(-1,1))\n",
        "\n",
        "# get 10 folds indexes (stratified k-fold can only be used in classification problems)\n",
        "kf = KFold(n_splits=10)\n",
        "kf.get_n_splits(X, y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YFLrW10y3P2"
      },
      "source": [
        "### Construção e Avaliação dos Modelos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaeIw4O8y8Z5",
        "outputId": "91ed1dfd-3b44-4daa-9907-064596aab7b0"
      },
      "source": [
        "parameters = [[0.5, 0.7, 1], ['mse', 'mae', \"friedman_mse\"]]\n",
        "\n",
        "for train_index, test_index in kf.split(X_scaled, y):\n",
        "  X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "  for i in range(3):\n",
        "    elanet = ElasticNet(alpha=parameters[0][i], random_state=17).fit(X_train, y_train)\n",
        "    dectree = DecisionTreeRegressor(criterion=parameters[1][i], random_state=17).fit(X_train, y_train)\n",
        "    elanet_preds = elanet.predict(X_test)\n",
        "    dectree_preds = dectree.predict(X_test)\n",
        "\n",
        "    print(\"\\nElastic Net\")\n",
        "    print(\"alpha=\",parameters[0][i])\n",
        "    print(\"Root Mean Squared Error: \", np.sqrt(sk.metrics.mean_squared_error(y_test, elanet_preds)))\n",
        "    print(\"\\nDecision Tree Regressor\")\n",
        "    print(\"criterion=\", parameters[1][i])\n",
        "    print(\"Root Mean Squared Error: \", np.sqrt(sk.metrics.mean_squared_error(y_test, dectree_preds)))\n",
        "    print(\"---------------------------------------------\")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Elastic Net\n",
            "alpha= 0.5\n",
            "Root Mean Squared Error:  28183.516278979787\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mse\n",
            "Root Mean Squared Error:  40459.49985208445\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.7\n",
            "Root Mean Squared Error:  28427.173700378906\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mae\n",
            "Root Mean Squared Error:  38569.33338567142\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 1\n",
            "Root Mean Squared Error:  28746.04367179864\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= friedman_mse\n",
            "Root Mean Squared Error:  40459.49985208445\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.5\n",
            "Root Mean Squared Error:  32659.84563339252\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mse\n",
            "Root Mean Squared Error:  42641.045507017145\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.7\n",
            "Root Mean Squared Error:  33070.84685295702\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mae\n",
            "Root Mean Squared Error:  45689.918234035795\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 1\n",
            "Root Mean Squared Error:  33533.618873483465\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= friedman_mse\n",
            "Root Mean Squared Error:  42641.045507017145\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.5\n",
            "Root Mean Squared Error:  28900.39099630879\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mse\n",
            "Root Mean Squared Error:  36132.62017577916\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.7\n",
            "Root Mean Squared Error:  29104.024645865495\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mae\n",
            "Root Mean Squared Error:  34204.615896844756\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 1\n",
            "Root Mean Squared Error:  29384.099362774185\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= friedman_mse\n",
            "Root Mean Squared Error:  36132.62017577916\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.5\n",
            "Root Mean Squared Error:  43293.59724266232\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mse\n",
            "Root Mean Squared Error:  60921.8252114617\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.7\n",
            "Root Mean Squared Error:  43581.68112595543\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mae\n",
            "Root Mean Squared Error:  42113.37084658082\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 1\n",
            "Root Mean Squared Error:  43942.148932346\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= friedman_mse\n",
            "Root Mean Squared Error:  60921.8252114617\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.5\n",
            "Root Mean Squared Error:  43962.13382242423\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mse\n",
            "Root Mean Squared Error:  43253.13436120547\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.7\n",
            "Root Mean Squared Error:  44188.3291631019\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mae\n",
            "Root Mean Squared Error:  40854.41542173936\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 1\n",
            "Root Mean Squared Error:  44464.65226333394\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= friedman_mse\n",
            "Root Mean Squared Error:  43253.13436120547\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.5\n",
            "Root Mean Squared Error:  33568.465870775246\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mse\n",
            "Root Mean Squared Error:  34110.29314591125\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.7\n",
            "Root Mean Squared Error:  33625.95170520045\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mae\n",
            "Root Mean Squared Error:  39478.36679136687\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 1\n",
            "Root Mean Squared Error:  33686.76400047303\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= friedman_mse\n",
            "Root Mean Squared Error:  34110.29314591125\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.5\n",
            "Root Mean Squared Error:  33164.226103338806\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mse\n",
            "Root Mean Squared Error:  27436.440902266488\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.7\n",
            "Root Mean Squared Error:  33516.36766907869\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mae\n",
            "Root Mean Squared Error:  32656.285388628658\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 1\n",
            "Root Mean Squared Error:  33935.980314761655\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= friedman_mse\n",
            "Root Mean Squared Error:  27436.440902266488\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.5\n",
            "Root Mean Squared Error:  31363.32597172884\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mse\n",
            "Root Mean Squared Error:  34309.145824904896\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.7\n",
            "Root Mean Squared Error:  31468.338117291423\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mae\n",
            "Root Mean Squared Error:  37213.07202338727\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 1\n",
            "Root Mean Squared Error:  31623.22988597078\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= friedman_mse\n",
            "Root Mean Squared Error:  34309.145824904896\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.5\n",
            "Root Mean Squared Error:  63874.772442171576\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mse\n",
            "Root Mean Squared Error:  65280.1400996096\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.7\n",
            "Root Mean Squared Error:  64546.269388972796\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mae\n",
            "Root Mean Squared Error:  45079.312800383224\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 1\n",
            "Root Mean Squared Error:  65336.84284760111\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= friedman_mse\n",
            "Root Mean Squared Error:  65280.1400996096\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.5\n",
            "Root Mean Squared Error:  29634.165527247027\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mse\n",
            "Root Mean Squared Error:  38271.92075317081\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 0.7\n",
            "Root Mean Squared Error:  29929.00529863217\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= mae\n",
            "Root Mean Squared Error:  42159.86800345197\n",
            "---------------------------------------------\n",
            "\n",
            "Elastic Net\n",
            "alpha= 1\n",
            "Root Mean Squared Error:  30278.642590188552\n",
            "\n",
            "Decision Tree Regressor\n",
            "criterion= friedman_mse\n",
            "Root Mean Squared Error:  38271.92075317081\n",
            "---------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnIGoWiaV44H"
      },
      "source": [
        "Como pode-se observar, o menor valor para a métrica RMSE foi obtido pelo modelo composto por uma Árvore de Decisão."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRQW5KBRtbyr"
      },
      "source": [
        "# Questão `III`\n",
        "https://www.kaggle.com/thesiff/premierleague1819"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwA5MQZi0L5R"
      },
      "source": [
        "### Aquisição e Análise Exploratória dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "mzGR-guzz1ig",
        "outputId": "237e622b-c91e-4577-8725-1521ed65c463"
      },
      "source": [
        "Train = pd.read_csv(\"https://raw.githubusercontent.com/J0AZZ/artificial-intelligence_studies/master/IAIA-UFPB/Prova%202/epl_1819.csv\")\n",
        "Train.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Team</th>\n",
              "      <th>category</th>\n",
              "      <th>general_league_position</th>\n",
              "      <th>finance _live_games_televised</th>\n",
              "      <th>finance _tv_revenue</th>\n",
              "      <th>general_matches_played</th>\n",
              "      <th>general_won</th>\n",
              "      <th>general_draw</th>\n",
              "      <th>general_lost</th>\n",
              "      <th>attack_scored</th>\n",
              "      <th>defence_goals_conceeded</th>\n",
              "      <th>general_goal_difference</th>\n",
              "      <th>general_points</th>\n",
              "      <th>general_squad_size</th>\n",
              "      <th>general_squad_average_age</th>\n",
              "      <th>general_squad_foreigners</th>\n",
              "      <th>finance _team_market</th>\n",
              "      <th>finance _market_average</th>\n",
              "      <th>attack_passes</th>\n",
              "      <th>attack_passes_through</th>\n",
              "      <th>attack_passes_long</th>\n",
              "      <th>attack_passes_back</th>\n",
              "      <th>attack_crosses</th>\n",
              "      <th>attack_corners_taken</th>\n",
              "      <th>attack_shots</th>\n",
              "      <th>attack_shots_on_target</th>\n",
              "      <th>attack_goals_headed</th>\n",
              "      <th>attack_goals_penalty</th>\n",
              "      <th>attack_goals_box</th>\n",
              "      <th>attack_goals_outsidebox</th>\n",
              "      <th>general_card_yellow</th>\n",
              "      <th>general_card_red</th>\n",
              "      <th>attack_goals_counter</th>\n",
              "      <th>attack_goals_freekick</th>\n",
              "      <th>defence_saves</th>\n",
              "      <th>defence_blocks</th>\n",
              "      <th>defence_interceptions</th>\n",
              "      <th>defence_tackles</th>\n",
              "      <th>defence_tackles_last_man</th>\n",
              "      <th>defence_clearances</th>\n",
              "      <th>defence_clearances_headed</th>\n",
              "      <th>defence_penalty_conceeded</th>\n",
              "      <th>attack_posession</th>\n",
              "      <th>attack_pass_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Manchester City</td>\n",
              "      <td>Champions League</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>150986355</td>\n",
              "      <td>38</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>95</td>\n",
              "      <td>23</td>\n",
              "      <td>72</td>\n",
              "      <td>98</td>\n",
              "      <td>25</td>\n",
              "      <td>27.1</td>\n",
              "      <td>20</td>\n",
              "      <td>1003200000</td>\n",
              "      <td>39987200</td>\n",
              "      <td>26,581</td>\n",
              "      <td>112</td>\n",
              "      <td>1,814</td>\n",
              "      <td>4,240</td>\n",
              "      <td>783</td>\n",
              "      <td>298</td>\n",
              "      <td>683</td>\n",
              "      <td>260</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>80</td>\n",
              "      <td>15</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>58</td>\n",
              "      <td>63</td>\n",
              "      <td>362</td>\n",
              "      <td>518</td>\n",
              "      <td>0</td>\n",
              "      <td>543</td>\n",
              "      <td>295</td>\n",
              "      <td>4</td>\n",
              "      <td>64.0</td>\n",
              "      <td>89.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Liverpool</td>\n",
              "      <td>Champions League</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "      <td>152425146</td>\n",
              "      <td>38</td>\n",
              "      <td>30</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>22</td>\n",
              "      <td>67</td>\n",
              "      <td>97</td>\n",
              "      <td>24</td>\n",
              "      <td>26.8</td>\n",
              "      <td>16</td>\n",
              "      <td>836440000</td>\n",
              "      <td>34848000</td>\n",
              "      <td>23,638</td>\n",
              "      <td>98</td>\n",
              "      <td>2,250</td>\n",
              "      <td>3,416</td>\n",
              "      <td>721</td>\n",
              "      <td>249</td>\n",
              "      <td>575</td>\n",
              "      <td>226</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>84</td>\n",
              "      <td>5</td>\n",
              "      <td>38</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>76</td>\n",
              "      <td>78</td>\n",
              "      <td>314</td>\n",
              "      <td>610</td>\n",
              "      <td>2</td>\n",
              "      <td>639</td>\n",
              "      <td>317</td>\n",
              "      <td>1</td>\n",
              "      <td>58.8</td>\n",
              "      <td>84.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Chelsea</td>\n",
              "      <td>Champions League Qualification</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>146030216</td>\n",
              "      <td>38</td>\n",
              "      <td>21</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>63</td>\n",
              "      <td>39</td>\n",
              "      <td>24</td>\n",
              "      <td>72</td>\n",
              "      <td>26</td>\n",
              "      <td>28.1</td>\n",
              "      <td>19</td>\n",
              "      <td>779460000</td>\n",
              "      <td>29981600</td>\n",
              "      <td>25,070</td>\n",
              "      <td>146</td>\n",
              "      <td>1,774</td>\n",
              "      <td>3,874</td>\n",
              "      <td>692</td>\n",
              "      <td>215</td>\n",
              "      <td>607</td>\n",
              "      <td>198</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>54</td>\n",
              "      <td>9</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>73</td>\n",
              "      <td>351</td>\n",
              "      <td>618</td>\n",
              "      <td>2</td>\n",
              "      <td>593</td>\n",
              "      <td>330</td>\n",
              "      <td>2</td>\n",
              "      <td>59.9</td>\n",
              "      <td>87.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tottenham</td>\n",
              "      <td>Champions League Qualification</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>145230801</td>\n",
              "      <td>38</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>67</td>\n",
              "      <td>39</td>\n",
              "      <td>28</td>\n",
              "      <td>71</td>\n",
              "      <td>25</td>\n",
              "      <td>27.0</td>\n",
              "      <td>17</td>\n",
              "      <td>735240000</td>\n",
              "      <td>29409600</td>\n",
              "      <td>21,295</td>\n",
              "      <td>87</td>\n",
              "      <td>2,267</td>\n",
              "      <td>3,191</td>\n",
              "      <td>643</td>\n",
              "      <td>194</td>\n",
              "      <td>537</td>\n",
              "      <td>189</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>53</td>\n",
              "      <td>14</td>\n",
              "      <td>56</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>121</td>\n",
              "      <td>112</td>\n",
              "      <td>326</td>\n",
              "      <td>626</td>\n",
              "      <td>3</td>\n",
              "      <td>770</td>\n",
              "      <td>411</td>\n",
              "      <td>5</td>\n",
              "      <td>56.7</td>\n",
              "      <td>83.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Arsenal</td>\n",
              "      <td>Europa League</td>\n",
              "      <td>5</td>\n",
              "      <td>25</td>\n",
              "      <td>142193180</td>\n",
              "      <td>38</td>\n",
              "      <td>21</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>73</td>\n",
              "      <td>51</td>\n",
              "      <td>22</td>\n",
              "      <td>70</td>\n",
              "      <td>26</td>\n",
              "      <td>27.5</td>\n",
              "      <td>18</td>\n",
              "      <td>701800000</td>\n",
              "      <td>26989600</td>\n",
              "      <td>20,805</td>\n",
              "      <td>65</td>\n",
              "      <td>2,062</td>\n",
              "      <td>3,102</td>\n",
              "      <td>605</td>\n",
              "      <td>209</td>\n",
              "      <td>467</td>\n",
              "      <td>170</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>62</td>\n",
              "      <td>11</td>\n",
              "      <td>72</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>133</td>\n",
              "      <td>118</td>\n",
              "      <td>412</td>\n",
              "      <td>609</td>\n",
              "      <td>2</td>\n",
              "      <td>762</td>\n",
              "      <td>404</td>\n",
              "      <td>7</td>\n",
              "      <td>56.1</td>\n",
              "      <td>83.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Team  ... attack_pass_accuracy\n",
              "0  Manchester City  ...                 89.0\n",
              "1        Liverpool  ...                 84.4\n",
              "2          Chelsea  ...                 87.6\n",
              "3        Tottenham  ...                 83.2\n",
              "4          Arsenal  ...                 83.3\n",
              "\n",
              "[5 rows x 44 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rtKvrfXa0SbO",
        "outputId": "26c91084-39d8-45e3-be76-1c150f603846"
      },
      "source": [
        "print(\"Shape: \", Train.shape, \"\\n\\n\", Train.info())\n",
        "stats = Train.describe()\n",
        "numerical_labels = stats.columns\n",
        "stats"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20 entries, 0 to 19\n",
            "Data columns (total 44 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   Team                           20 non-null     object \n",
            " 1   category                       20 non-null     object \n",
            " 2   general_league_position        20 non-null     int64  \n",
            " 3   finance _live_games_televised  20 non-null     int64  \n",
            " 4   finance _tv_revenue            20 non-null     int64  \n",
            " 5   general_matches_played         20 non-null     int64  \n",
            " 6   general_won                    20 non-null     int64  \n",
            " 7   general_draw                   20 non-null     int64  \n",
            " 8   general_lost                   20 non-null     int64  \n",
            " 9   attack_scored                  20 non-null     int64  \n",
            " 10  defence_goals_conceeded        20 non-null     int64  \n",
            " 11  general_goal_difference        20 non-null     int64  \n",
            " 12  general_points                 20 non-null     int64  \n",
            " 13  general_squad_size             20 non-null     int64  \n",
            " 14  general_squad_average_age      20 non-null     float64\n",
            " 15  general_squad_foreigners       20 non-null     int64  \n",
            " 16  finance _team_market           20 non-null     int64  \n",
            " 17  finance _market_average        20 non-null     int64  \n",
            " 18  attack_passes                  20 non-null     object \n",
            " 19  attack_passes_through          20 non-null     int64  \n",
            " 20  attack_passes_long             20 non-null     object \n",
            " 21  attack_passes_back             20 non-null     object \n",
            " 22  attack_crosses                 20 non-null     int64  \n",
            " 23  attack_corners_taken           20 non-null     int64  \n",
            " 24  attack_shots                   20 non-null     int64  \n",
            " 25  attack_shots_on_target         20 non-null     int64  \n",
            " 26  attack_goals_headed            20 non-null     int64  \n",
            " 27  attack_goals_penalty           20 non-null     int64  \n",
            " 28  attack_goals_box               20 non-null     int64  \n",
            " 29  attack_goals_outsidebox        20 non-null     int64  \n",
            " 30  general_card_yellow            20 non-null     int64  \n",
            " 31  general_card_red               20 non-null     int64  \n",
            " 32  attack_goals_counter           20 non-null     int64  \n",
            " 33  attack_goals_freekick          20 non-null     int64  \n",
            " 34  defence_saves                  20 non-null     int64  \n",
            " 35  defence_blocks                 20 non-null     int64  \n",
            " 36  defence_interceptions          20 non-null     int64  \n",
            " 37  defence_tackles                20 non-null     int64  \n",
            " 38  defence_tackles_last_man       20 non-null     int64  \n",
            " 39  defence_clearances             20 non-null     object \n",
            " 40  defence_clearances_headed      20 non-null     int64  \n",
            " 41  defence_penalty_conceeded      20 non-null     int64  \n",
            " 42  attack_posession               20 non-null     float64\n",
            " 43  attack_pass_accuracy           20 non-null     float64\n",
            "dtypes: float64(3), int64(35), object(6)\n",
            "memory usage: 7.0+ KB\n",
            "Shape:  (20, 44) \n",
            "\n",
            " None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>general_league_position</th>\n",
              "      <th>finance _live_games_televised</th>\n",
              "      <th>finance _tv_revenue</th>\n",
              "      <th>general_matches_played</th>\n",
              "      <th>general_won</th>\n",
              "      <th>general_draw</th>\n",
              "      <th>general_lost</th>\n",
              "      <th>attack_scored</th>\n",
              "      <th>defence_goals_conceeded</th>\n",
              "      <th>general_goal_difference</th>\n",
              "      <th>general_points</th>\n",
              "      <th>general_squad_size</th>\n",
              "      <th>general_squad_average_age</th>\n",
              "      <th>general_squad_foreigners</th>\n",
              "      <th>finance _team_market</th>\n",
              "      <th>finance _market_average</th>\n",
              "      <th>attack_passes_through</th>\n",
              "      <th>attack_crosses</th>\n",
              "      <th>attack_corners_taken</th>\n",
              "      <th>attack_shots</th>\n",
              "      <th>attack_shots_on_target</th>\n",
              "      <th>attack_goals_headed</th>\n",
              "      <th>attack_goals_penalty</th>\n",
              "      <th>attack_goals_box</th>\n",
              "      <th>attack_goals_outsidebox</th>\n",
              "      <th>general_card_yellow</th>\n",
              "      <th>general_card_red</th>\n",
              "      <th>attack_goals_counter</th>\n",
              "      <th>attack_goals_freekick</th>\n",
              "      <th>defence_saves</th>\n",
              "      <th>defence_blocks</th>\n",
              "      <th>defence_interceptions</th>\n",
              "      <th>defence_tackles</th>\n",
              "      <th>defence_tackles_last_man</th>\n",
              "      <th>defence_clearances_headed</th>\n",
              "      <th>defence_penalty_conceeded</th>\n",
              "      <th>attack_posession</th>\n",
              "      <th>attack_pass_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20.00000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>2.000000e+01</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.00000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>2.000000e+01</td>\n",
              "      <td>2.000000e+01</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10.50000</td>\n",
              "      <td>17.100000</td>\n",
              "      <td>1.228004e+08</td>\n",
              "      <td>38.0</td>\n",
              "      <td>15.450000</td>\n",
              "      <td>7.10000</td>\n",
              "      <td>15.450000</td>\n",
              "      <td>53.600000</td>\n",
              "      <td>53.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>53.450000</td>\n",
              "      <td>25.250000</td>\n",
              "      <td>27.490000</td>\n",
              "      <td>17.450000</td>\n",
              "      <td>3.750362e+08</td>\n",
              "      <td>1.498508e+07</td>\n",
              "      <td>58.700000</td>\n",
              "      <td>666.650000</td>\n",
              "      <td>195.350000</td>\n",
              "      <td>481.650000</td>\n",
              "      <td>165.550000</td>\n",
              "      <td>9.300000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>46.400000</td>\n",
              "      <td>7.250000</td>\n",
              "      <td>61.100000</td>\n",
              "      <td>2.350000</td>\n",
              "      <td>3.350000</td>\n",
              "      <td>1.150000</td>\n",
              "      <td>111.950000</td>\n",
              "      <td>127.750000</td>\n",
              "      <td>429.300000</td>\n",
              "      <td>646.250000</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>429.400000</td>\n",
              "      <td>5.350000</td>\n",
              "      <td>49.995000</td>\n",
              "      <td>78.310000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.91608</td>\n",
              "      <td>6.734827</td>\n",
              "      <td>1.821686e+07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.250953</td>\n",
              "      <td>2.44734</td>\n",
              "      <td>6.778255</td>\n",
              "      <td>18.071204</td>\n",
              "      <td>15.752694</td>\n",
              "      <td>32.371202</td>\n",
              "      <td>21.007455</td>\n",
              "      <td>1.802776</td>\n",
              "      <td>0.938588</td>\n",
              "      <td>4.071402</td>\n",
              "      <td>2.821444e+08</td>\n",
              "      <td>1.127381e+07</td>\n",
              "      <td>33.625022</td>\n",
              "      <td>75.524325</td>\n",
              "      <td>34.776391</td>\n",
              "      <td>78.333481</td>\n",
              "      <td>39.323858</td>\n",
              "      <td>3.934998</td>\n",
              "      <td>2.546411</td>\n",
              "      <td>16.044018</td>\n",
              "      <td>4.165965</td>\n",
              "      <td>10.557611</td>\n",
              "      <td>1.424411</td>\n",
              "      <td>2.433862</td>\n",
              "      <td>1.136708</td>\n",
              "      <td>24.267099</td>\n",
              "      <td>37.160923</td>\n",
              "      <td>71.058982</td>\n",
              "      <td>65.310493</td>\n",
              "      <td>1.880649</td>\n",
              "      <td>84.536756</td>\n",
              "      <td>2.109502</td>\n",
              "      <td>6.387692</td>\n",
              "      <td>5.866129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.662886e+07</td>\n",
              "      <td>38.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>-54.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>26.100000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>8.549200e+07</td>\n",
              "      <td>3.053600e+06</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>562.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>360.000000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>314.000000</td>\n",
              "      <td>518.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>246.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>39.100000</td>\n",
              "      <td>63.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.75000</td>\n",
              "      <td>11.750000</td>\n",
              "      <td>1.069409e+08</td>\n",
              "      <td>38.0</td>\n",
              "      <td>10.750000</td>\n",
              "      <td>6.75000</td>\n",
              "      <td>12.250000</td>\n",
              "      <td>44.250000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>-20.750000</td>\n",
              "      <td>39.750000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>26.800000</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>1.723480e+08</td>\n",
              "      <td>6.747400e+06</td>\n",
              "      <td>34.500000</td>\n",
              "      <td>612.500000</td>\n",
              "      <td>174.750000</td>\n",
              "      <td>440.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>38.500000</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>55.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.750000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>364.250000</td>\n",
              "      <td>604.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>390.250000</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>46.300000</td>\n",
              "      <td>75.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>10.50000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>1.213295e+08</td>\n",
              "      <td>38.0</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>7.00000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>51.500000</td>\n",
              "      <td>53.500000</td>\n",
              "      <td>-2.500000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>25.500000</td>\n",
              "      <td>27.250000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>2.317260e+08</td>\n",
              "      <td>9.935200e+06</td>\n",
              "      <td>50.500000</td>\n",
              "      <td>640.500000</td>\n",
              "      <td>193.500000</td>\n",
              "      <td>472.000000</td>\n",
              "      <td>159.500000</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>59.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>434.500000</td>\n",
              "      <td>655.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>48.350000</td>\n",
              "      <td>78.150000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15.25000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>1.422731e+08</td>\n",
              "      <td>38.0</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>9.00000</td>\n",
              "      <td>19.250000</td>\n",
              "      <td>63.500000</td>\n",
              "      <td>65.750000</td>\n",
              "      <td>13.750000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>28.150000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>5.882800e+08</td>\n",
              "      <td>2.326060e+07</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>713.500000</td>\n",
              "      <td>209.250000</td>\n",
              "      <td>517.750000</td>\n",
              "      <td>185.250000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>53.250000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>71.250000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>128.500000</td>\n",
              "      <td>147.250000</td>\n",
              "      <td>472.500000</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>499.250000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>82.525000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>20.00000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>1.524251e+08</td>\n",
              "      <td>38.0</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>12.00000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>29.700000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>1.003200e+09</td>\n",
              "      <td>3.998720e+07</td>\n",
              "      <td>146.000000</td>\n",
              "      <td>814.000000</td>\n",
              "      <td>298.000000</td>\n",
              "      <td>683.000000</td>\n",
              "      <td>260.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>222.000000</td>\n",
              "      <td>548.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>564.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>89.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       general_league_position  ...  attack_pass_accuracy\n",
              "count                 20.00000  ...             20.000000\n",
              "mean                  10.50000  ...             78.310000\n",
              "std                    5.91608  ...              5.866129\n",
              "min                    1.00000  ...             63.900000\n",
              "25%                    5.75000  ...             75.550000\n",
              "50%                   10.50000  ...             78.150000\n",
              "75%                   15.25000  ...             82.525000\n",
              "max                   20.00000  ...             89.000000\n",
              "\n",
              "[8 rows x 38 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ76f_J21MJU",
        "outputId": "ce5c7e45-7a33-4337-a2a2-1b7db0556331"
      },
      "source": [
        "# take relevant attributes\n",
        "relevant_corr = Train.corr()[abs(Train.corr()[\"general_league_position\"]) > 0.7][\"general_league_position\"]\n",
        "relevant_corr"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "general_league_position          1.000000\n",
              "finance _live_games_televised   -0.854654\n",
              "finance _tv_revenue             -0.976656\n",
              "general_won                     -0.940436\n",
              "general_lost                     0.944333\n",
              "attack_scored                   -0.900407\n",
              "defence_goals_conceeded          0.906426\n",
              "general_goal_difference         -0.943743\n",
              "general_points                  -0.953902\n",
              "finance _team_market            -0.914043\n",
              "finance _market_average         -0.914010\n",
              "attack_passes_through           -0.803781\n",
              "attack_corners_taken            -0.795460\n",
              "attack_shots                    -0.812425\n",
              "attack_shots_on_target          -0.840569\n",
              "attack_goals_box                -0.879432\n",
              "defence_blocks                   0.703480\n",
              "attack_posession                -0.849220\n",
              "attack_pass_accuracy            -0.779514\n",
              "Name: general_league_position, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "ukLDtug53A_7",
        "outputId": "5c58bbcc-ca6c-4e23-df07-8af601a6dbfd"
      },
      "source": [
        "# here we can take a look at the distribution of some important variables\n",
        "Train[[\"general_league_position\",\"general_won\"]].hist(bins=100)\n",
        "# we can see that general_league_position assumes a uniform distribution, \n",
        "# it's mean is equal to it's median, and, finally,\n",
        "# that general_won tends to a normal distribution\n",
        "print(Train[\"general_league_position\"].describe())\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    20.00000\n",
            "mean     10.50000\n",
            "std       5.91608\n",
            "min       1.00000\n",
            "25%       5.75000\n",
            "50%      10.50000\n",
            "75%      15.25000\n",
            "max      20.00000\n",
            "Name: general_league_position, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK73mUiuGx76"
      },
      "source": [
        "### Pré-processamento dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AlgHDXQPcD67",
        "outputId": "36de4642-651c-4c10-9ff0-44dd5bfb3c52"
      },
      "source": [
        "# function for cleaning integers represented with comma\n",
        "def remove_comma(nan):\n",
        "  n = ''\n",
        "  for c in nan:\n",
        "    if (c == ','):\n",
        "      pass\n",
        "    else:\n",
        "      n += c\n",
        "  return n\n",
        "\n",
        "remove_comma('1,11,0')\n",
        "# it is better to perform str to int conversion with pandas methods"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1110'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EENjv80RERoM"
      },
      "source": [
        "# take variables that must be numbers but are represented as strings\n",
        "haphazard_numeric = Train.copy().drop(numerical_labels, axis=1).drop([\"Team\", \"category\"], axis=1)\n",
        "no_comma = []\n",
        "for col in haphazard_numeric:\n",
        "  no_comma.append(pd.DataFrame([remove_comma(haphazard_numeric[col][i]) for i in range(20)]))\n",
        "\n",
        "# make new dataframe\n",
        "integers = pd.concat(no_comma, axis=1)\n",
        "integers.columns = [\"attack_passes\", \"attack_passes_long\", \"attack_passes_back\", \"defence_clearances\"]\n",
        "\n",
        "# our dataset is composed from the most correlated variables with respect to general_league_position\n",
        "dataset = pd.concat([integers, Train[relevant_corr.keys()]], axis=1)\n",
        "X = dataset.copy()\n",
        "y = Train[\"category\"]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANyD6Ytv3w95"
      },
      "source": [
        "### Construção e Avaliação dos Modelos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJQZqLmcuf04",
        "outputId": "d77893f6-c800-4372-8c0c-f47bcee6aa33"
      },
      "source": [
        "# train test splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)\n",
        "\n",
        "# 5 different values for k\n",
        "for k in [2, 3, 4, 5, 6]:\n",
        "  # K Means\n",
        "  kmeans = KMeans(n_clusters=k, random_state=17).fit(X_train, y_train)\n",
        "  kmeans_preds = kmeans.predict(X_test)\n",
        "  print(\"K Médias\\nk=\", k)\n",
        "  print(\"Homogeneity Score=\", sk.metrics.homogeneity_score(y_test, kmeans_preds))\n",
        "  print(\"Completeness Score =\", sk.metrics.completeness_score(y_test, kmeans_preds))\n",
        "\n",
        "  # Hierarchical Clustering\n",
        "  for linkage in ['complete', 'single']:\n",
        "    hierarch = AgglomerativeClustering(n_clusters=k, linkage=linkage)\n",
        "    hierarch_preds = hierarch.fit_predict(X_test)\n",
        "    print(\"\\nAgrupamento Hierárquico\\nlinkage=\", linkage, \"\\nk=\",k)\n",
        "    print(\"Homogeneity Score =\", sk.metrics.homogeneity_score(y_test, hierarch_preds))\n",
        "    print(\"Completeness Score =\", sk.metrics.completeness_score(y_test, hierarch_preds))\n",
        "  print(\"---------------------------------------\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K Médias\n",
            "k= 2\n",
            "Homogeneity Score= 1.0\n",
            "Completeness Score = 1.0\n",
            "\n",
            "Agrupamento Hierárquico\n",
            "linkage= complete \n",
            "k= 2\n",
            "Homogeneity Score = 1.0\n",
            "Completeness Score = 1.0\n",
            "\n",
            "Agrupamento Hierárquico\n",
            "linkage= single \n",
            "k= 2\n",
            "Homogeneity Score = 1.0\n",
            "Completeness Score = 1.0\n",
            "---------------------------------------\n",
            "K Médias\n",
            "k= 3\n",
            "Homogeneity Score= 1.0\n",
            "Completeness Score = 1.0\n",
            "\n",
            "Agrupamento Hierárquico\n",
            "linkage= complete \n",
            "k= 3\n",
            "Homogeneity Score = 1.0000000000000002\n",
            "Completeness Score = 0.5193410625009365\n",
            "\n",
            "Agrupamento Hierárquico\n",
            "linkage= single \n",
            "k= 3\n",
            "Homogeneity Score = 1.0000000000000002\n",
            "Completeness Score = 0.5193410625009365\n",
            "---------------------------------------\n",
            "K Médias\n",
            "k= 4\n",
            "Homogeneity Score= 1.0\n",
            "Completeness Score = 1.0\n",
            "\n",
            "Agrupamento Hierárquico\n",
            "linkage= complete \n",
            "k= 4\n",
            "Homogeneity Score = 0.9999999999999998\n",
            "Completeness Score = 0.33885410691555\n",
            "\n",
            "Agrupamento Hierárquico\n",
            "linkage= single \n",
            "k= 4\n",
            "Homogeneity Score = 1.0000000000000002\n",
            "Completeness Score = 0.3626383380677455\n",
            "---------------------------------------\n",
            "K Médias\n",
            "k= 5\n",
            "Homogeneity Score= 0.9999999999999999\n",
            "Completeness Score = 0.4454808275864586\n",
            "\n",
            "Agrupamento Hierárquico\n",
            "linkage= complete \n",
            "k= 5\n",
            "Homogeneity Score = 1.0\n",
            "Completeness Score = 0.28868982115845626\n",
            "\n",
            "Agrupamento Hierárquico\n",
            "linkage= single \n",
            "k= 5\n",
            "Homogeneity Score = 1.0\n",
            "Completeness Score = 0.28868982115845626\n",
            "---------------------------------------\n",
            "K Médias\n",
            "k= 6\n",
            "Homogeneity Score= 1.0000000000000002\n",
            "Completeness Score = 0.3626383380677455\n",
            "\n",
            "Agrupamento Hierárquico\n",
            "linkage= complete \n",
            "k= 6\n",
            "Homogeneity Score = 1.0000000000000002\n",
            "Completeness Score = 0.25146299858006077\n",
            "\n",
            "Agrupamento Hierárquico\n",
            "linkage= single \n",
            "k= 6\n",
            "Homogeneity Score = 1.0000000000000002\n",
            "Completeness Score = 0.25146299858006077\n",
            "---------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}