{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Particionando-bases-de-treino-e-teste-com-split-70-30%\" data-toc-modified-id=\"Particionando-bases-de-treino-e-teste-com-split-70-30%-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Particionando bases de treino e teste com split 70-30%</a></span></li><li><span><a href=\"#Particionando-bases-de-treino-e-teste-com-diferentes-músicas\" data-toc-modified-id=\"Particionando-bases-de-treino-e-teste-com-diferentes-músicas-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Particionando bases de treino e teste com diferentes músicas</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('E:\\chord-detection-challenge\\DataBase\\CSV/status_A1.csv')\n",
    "df.sort_values(by='title', inplace=True)\n",
    "images_path = sorted(glob.glob('E:\\chord-detection-challenge\\DataBase\\clean_windows/Train/*'))\n",
    "df['Unnamed: 0'] = np.array(images_path)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df['status'] = df['status'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particionando bases de treino e teste com split 70-30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imagens de treinamento 7648\n",
      "Total de imagens de validação 3278\n",
      "Total de imagens de teste 4683\n"
     ]
    }
   ],
   "source": [
    "### particiona considerando 70-30% e mantendo a frequência de amostras para treino, validação e teste de acordo com as colunas título e status (rótulo da rede)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['Unnamed: 0', 'title']], df['status'], test_size=0.30, random_state=42, stratify=df[['status', 'title']])\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_train[['Unnamed: 0', 'title']], df_train['status'], test_size=0.30, random_state=42, stratify=df_train[['status', 'title']])\n",
    "\n",
    "### contatena atributos de entrada e rótulo em um único dataframe para utilizar o flow_from_dataframe do tensorflow\n",
    "df_test = pd.concat([X_test, y_test], axis=1)\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_val = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "print('Total de imagens de treinamento', len(df_train))\n",
    "print('Total de imagens de validação', len(df_val))\n",
    "print('Total de imagens de teste', len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample_train = RandomUnderSampler(sampling_strategy='majority')\n",
    "undersample_validation = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "X_undertrain, y_undertrain = undersample_train.fit_resample(df_train[['Unnamed: 0', 'title']], df_train['status'])\n",
    "X_undervalidation, y_undervalidation = undersample_validation.fit_resample(df_val[['Unnamed: 0', 'title']], df_val['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_undertrain, y_undertrain], axis=1)\n",
    "df_val = pd.concat([X_undervalidation, y_undervalidation], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particionando bases de treino e teste com diferentes músicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imagens de treinamento 9591\n",
      "Total de imagens de validação 4111\n",
      "Total de imagens de teste 1907\n"
     ]
    }
   ],
   "source": [
    "songs, n = df['title'].unique(), 5\n",
    "index = np.random.choice(len(songs), 5, replace=False)  \n",
    "selected_songs = songs[index] ## seleciona n músicas disponíveis para teste\n",
    "df_test = df[df['title'].isin(selected_songs)] ## banco de teste contém todos os espectrogramas das n músicas selecionadas anteriormemente\n",
    "df_train = df[~(df['title'].isin(selected_songs))] ## banco de treino contém os espectrogramas de todas as músicas EXCETO as selecionadas anteriormente para teste\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_train[['Unnamed: 0', 'title']], df_train['status'], test_size=0.30, random_state=42, stratify=df_train[['status', 'title']]) ## divide em validação considerando 30% e balanceamento de acordo com título e status\n",
    "\n",
    "### contatena atributos de entrada e rótulo em um único dataframe para utilizar o flow_from_dataframe do tensorflow\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_val = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "print('Total de imagens de treinamento', len(df_train))\n",
    "print('Total de imagens de validação', len(df_val))\n",
    "print('Total de imagens de teste', len(df_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4494 validated image filenames belonging to 2 classes.\n",
      "Found 1926 validated image filenames belonging to 2 classes.\n",
      "Found 4683 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255)\n",
    "train_generator=datagen.flow_from_dataframe(dataframe=df_train, directory='E:\\chord-detection-challenge\\DataBase\\clean_windows/Train/', x_col='Unnamed: 0', y_col=\"status\", class_mode=\"binary\", target_size=(224,224), batch_size=32)\n",
    "valid_generator=datagen.flow_from_dataframe(dataframe=df_val, directory='E:\\chord-detection-challenge\\DataBase\\clean_windows/Train/', x_col='Unnamed: 0', y_col=\"status\", class_mode=\"binary\", target_size=(224,224), batch_size=32)\n",
    "test_generator=datagen.flow_from_dataframe(dataframe=df_test, directory='E:\\chord-detection-challenge\\DataBase\\clean_windows/Train/', x_col='Unnamed: 0', y_col=\"status\", class_mode=\"binary\", target_size=(224,224), batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.keras.models import Model\n",
    "restnet = tf.keras.applications.VGG16(\n",
    "    include_top=False, # não vai aproveitar a camada de saída \n",
    "    weights=None, #não pega os pesso da imagenet\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "output = restnet.layers[-1].output\n",
    "output = tf.keras.layers.Flatten()(output)\n",
    "restnet = tf.keras.Model(inputs=restnet.input, outputs=output)\n",
    "for layer in restnet.layers: #treina tudo do zero\n",
    "    layer.trainable = True\n",
    "restnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cflav\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=['0' '1'], y=0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "4489    1\n",
      "4490    1\n",
      "4491    1\n",
      "4492    1\n",
      "4493    1\n",
      "Name: status, Length: 4494, dtype: object as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "140/140 [==============================] - 214s 2s/step - loss: 0.7405 - binary_accuracy: 0.5027 - val_loss: 0.6931 - val_binary_accuracy: 0.5005\n",
      "Epoch 2/10\n",
      "140/140 [==============================] - 168s 1s/step - loss: 0.6932 - binary_accuracy: 0.4948 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "140/140 [==============================] - 169s 1s/step - loss: 0.6932 - binary_accuracy: 0.4939 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "140/140 [==============================] - 166s 1s/step - loss: 0.6931 - binary_accuracy: 0.5054 - val_loss: 0.6931 - val_binary_accuracy: 0.5010\n",
      "Epoch 5/10\n",
      "140/140 [==============================] - 156s 1s/step - loss: 0.6932 - binary_accuracy: 0.4931 - val_loss: 0.6931 - val_binary_accuracy: 0.4995\n",
      "Epoch 6/10\n",
      "140/140 [==============================] - 159s 1s/step - loss: 0.6932 - binary_accuracy: 0.4971 - val_loss: 0.6932 - val_binary_accuracy: 0.4995\n",
      "Epoch 7/10\n",
      "140/140 [==============================] - 151s 1s/step - loss: 0.6931 - binary_accuracy: 0.5007 - val_loss: 0.6931 - val_binary_accuracy: 0.5005\n",
      "Epoch 8/10\n",
      "140/140 [==============================] - 155s 1s/step - loss: 0.6932 - binary_accuracy: 0.4942 - val_loss: 0.6931 - val_binary_accuracy: 0.4995\n",
      "Epoch 9/10\n",
      "140/140 [==============================] - 161s 1s/step - loss: 0.6932 - binary_accuracy: 0.5016 - val_loss: 0.6931 - val_binary_accuracy: 0.5010\n",
      "Epoch 10/10\n",
      "140/140 [==============================] - 172s 1s/step - loss: 0.6932 - binary_accuracy: 0.4850 - val_loss: 0.6931 - val_binary_accuracy: 0.5005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d67953e370>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc = tf.keras.callbacks.ModelCheckpoint('resnet_model.h5', monitor='val_binary_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(restnet)\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu', input_dim=(224,224,3)))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "#   tf.keras.layers.Conv2D(32, (3, 3), padding='same',\n",
    "#                input_shape=(32,32,3)),\n",
    "#   tf.keras.layers.MaxPool2D(),\n",
    "#   tf.keras.layers.Conv2D(64, (3, 3)),\n",
    "#   tf.keras.layers.Conv2D(128, (3, 3)),\n",
    "#   tf.keras.layers.Flatten(),\n",
    "#   tf.keras.layers.Dense(128,activation='relu'),\n",
    "#   tf.keras.layers.Dense(2)\n",
    "#)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adamax(),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    "    #weighted_metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    ")\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(df_train['status']),\n",
    "                                                 df_train['status'])\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "model.fit(train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    #class_weight=class_weights,\n",
    "                    epochs=10,\n",
    "                    callbacks = [mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Teste-------------\n",
      "4683/4683 [==============================] - 122s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "\n",
    "print('---------------Teste-------------')\n",
    "test_generator.reset()\n",
    "predictions = model.predict(test_generator,\n",
    "                        steps=STEP_SIZE_TEST,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49953243],\n",
       "       [0.49953243],\n",
       "       [0.49953243],\n",
       "       ...,\n",
       "       [0.49953243],\n",
       "       [0.49953243],\n",
       "       [0.49953243]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictions > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(predictions,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29404228058936577\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_generator.labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3306\n",
      "           1       0.29      1.00      0.45      1377\n",
      "\n",
      "    accuracy                           0.29      4683\n",
      "   macro avg       0.15      0.50      0.23      4683\n",
      "weighted avg       0.09      0.29      0.13      4683\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cflav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\cflav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\cflav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_generator.labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
