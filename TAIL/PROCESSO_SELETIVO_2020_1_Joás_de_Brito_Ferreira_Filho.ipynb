{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "PROCESSO SELETIVO 2020.1 - Joás de Brito Ferreira Filho",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUsAkK2R2Pvr",
        "colab_type": "text"
      },
      "source": [
        "# <font color =\"darkblue\">Processo seletivo TAIL 2020.2</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCKsxbk52Pvt",
        "colab_type": "text"
      },
      "source": [
        "## Introdução"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf-7GwfF2Pvv",
        "colab_type": "text"
      },
      "source": [
        "Olá candidato! Para participar do 2º processo seletivo, você deve abrir o link do colab abaixo e fazer uma cópia para seu drive e inserir as respostas nos campos.\n",
        "\n",
        "Após responder, basta compartilhar conosco e nos enviar o link no email: tail.ufpb@gmail.com com o assunto **PROCESSO SELETIVO 2020.1 - SEU_NOME**\n",
        "\n",
        "Para mais instruções, assista o vídeo de explicações e dúvidas que enviamos por email."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJxKUwaJ2Pvw",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/TailUFPB/processo2fase/blob/master/Fase2_SEUNOME.ipynb) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNt6nwoa2Pvx",
        "colab_type": "text"
      },
      "source": [
        "## Instruções:\n",
        "<br>1. Abra o Google Colaboratory;\n",
        "<br>2. Faça uma cópia no seu drive;\n",
        "<br>3. Localize o notebook e abra-o;\n",
        "<br>4. Responda o questionário;\n",
        "<br>5. Salve o notebook e submeta-o através de nosso email: tail.ufpb@gmail.com\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fbCF0e52Pvy",
        "colab_type": "text"
      },
      "source": [
        "## Materiais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWFpF_Ha2Pvz",
        "colab_type": "text"
      },
      "source": [
        "**Anexo :** \n",
        "\n",
        "Para auxilio com as questões, disponibilizamos o livro *Python para Estatísticos*, do professor Telmo de Menezes e Silva Filho, do Departamento de Estatística da Universidade Federal da Paraíba (UFPB):\n",
        "\n",
        "[**Python para Estatísticos**](https://tmfilho.github.io/pyestbook)\n",
        "\n",
        "Link para bibliotecas essênciais para desenvolver os problemas abaixo:\n",
        "\n",
        "[**Bibliotecas essenciais**](https://github.com/Manuelfjr/processo2fase_anexo)\n",
        "\n",
        "Slides das aulas de Thais:  \n",
        "  \n",
        "[**Slides**](https://sites.google.com/site/gaudenciothaisia/home/aulas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BJIwbXqF2Pv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ebe2619a-f68d-4962-dfb4-e7ea877f144b"
      },
      "source": [
        "#@title Preencha os campos abaixo:\n",
        "\n",
        "nome = 'Joás de Brito Ferreira Filho' #@param {type:\"string\"}\n",
        "email = 'ferreira.joas.17@gmail.com' #@param {type:\"string\"}\n",
        "\n",
        "# confira se os valores impressos correspondem ao que você digitou\n",
        "print(nome)\n",
        "print(email)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Joás de Brito Ferreira Filho\n",
            "ferreira.joas.17@gmail.com\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3NAkOQk2Pv-",
        "colab_type": "text"
      },
      "source": [
        "## Avisos\n",
        "Aqui vão uma série de avisos e dicas:\n",
        "* Fiquem de boa galera. Isso não é uma prova e o seu desempenho aqui não é eliminatório.\n",
        "* Se esforcem. Mesmo que não consigam responder tudo, deem o máximo de si.\n",
        "* Descrevam o que pensaram e como fizeram ou teriam feito para resolver a questão (isso é muito importante).\n",
        "* Se divirtam. Vai ser muito legal ter vocês conosco!\n",
        "\n",
        "![](https://github.com/TailUFPB/processo2fase/raw/master/img/ygt.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZBrzRiv2Pv_",
        "colab_type": "text"
      },
      "source": [
        "# Dados e enunciado para as questões 1, 2 e 3:\n",
        "##### Data Set Information:\n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "1) ID number  \n",
        "2) Diagnosis (M = malignant, B = benign)\n",
        "\n",
        "Ten real-valued features are computed for each cell nucleus:\n",
        "\n",
        "a) radius (mean of distances from center to points on the perimeter)  \n",
        "b) texture (standard deviation of gray-scale values)  \n",
        "c) perimeter  \n",
        "d) area  \n",
        "e) smoothness (local variation in radius lengths)  \n",
        "f) compactness (perimeter^2 / area - 1.0)  \n",
        "g) concavity (severity of concave portions of the contour)  \n",
        "h) concave points (number of concave portions of the contour)  \n",
        "i) symmetry  \n",
        "j) fractal dimension (\"coastline approximation\" - 1)  \n",
        "\n",
        "*datapath: https://raw.githubusercontent.com/carlosfab/data_science/master/datasets/breast-cancer-wisconsin.csv*\n",
        "***\n",
        "### Questão 1: Preparação do ambiente\n",
        "\n",
        "**a)** Preparar o ambiente (Colab)  \n",
        "**b)** Pegar os arquivos que vão utilizar na tarefa  \n",
        "**c)** Utilizar o pandas para receber os dados  \n",
        "**d)** Visualizar os Dados em Histogramas  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvf9mJkJ2PwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# R: \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "datapath = 'https://raw.githubusercontent.com/carlosfab/data_science/master/datasets/breast-cancer-wisconsin.csv'\n",
        "dataset = pd.read_csv(datapath, index_col=0, sep=',')\n",
        "print(dataset.columns)\n",
        "data = [dataset.radius_mean, \n",
        "        dataset.texture_mean, \n",
        "        dataset.perimeter_mean,\n",
        "        dataset.area_mean,\n",
        "        dataset.smoothness_mean,\n",
        "        dataset.compactness_mean,\n",
        "        dataset.concavity_mean,\n",
        "        dataset.concavity_worst,\n",
        "        dataset.symmetry_mean,\n",
        "        dataset.fractal_dimension_mean]\n",
        "for i in range(10):\n",
        "    plt.hist(data[i], bins=50)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqw0rJip2PwF",
        "colab_type": "text"
      },
      "source": [
        "### Questão 2: Análise exploratória\n",
        "**a)** Visualize os dados, detalhando cada coluna  \n",
        "**b)** Extraia informações dos dados. Média, Moda, Mediana, Boxplot  \n",
        "**c)** Visualize os valores únicos de uma determinada coluna  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ2ly_eL2PwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# R: \n",
        "dataset.columns\n",
        "dataset\n",
        "\n",
        "mean = dataset.mean()\n",
        "mode = dataset.mode()\n",
        "median = dataset.median()\n",
        "boxplot = dataset.boxplot()\n",
        "\n",
        "some_column = dataset.diagnosis\n",
        "for data in some_column:\n",
        "    print(\"Diagnosis: \", data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLhb26AQ2PwN",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### Questão 3: Construa gráficos para passar uma mensagem sobre a análise que foi feita"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBhU2Sk-2PwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# R: \n",
        "basic_metrics = [mean, mode, median]\n",
        "plt.hist(dataset.diagnosis, bins=5)\n",
        "plt.show()\n",
        "for metric in basic_metrics:\n",
        "    plt.hist(metric.radius_mean, bins=5)\n",
        "plt.show()\n",
        "\n",
        "#the two histograms shows the distribution between the diagnosis observations and that the three basic statistics of the feature radius_mean are equal\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJmoC2ZK2PwX",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### Questão 4: Leitura de gráficos\n",
        "**Explique o que ocorre com os modelos treinados abaixo e identifique possíveis soluções para um melhor desempenho.**\n",
        "![img](https://i.imgur.com/00SO2Xh.jpg?1)\n",
        "![img](https://i.imgur.com/NS8Qc6f.png?1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcwzMrAR2Pwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# R: O modelo representado pelo segundo gráfico claramente se saiu melhor  do que o primeiro em seu processo de implementação, visto que:\n",
        "#       a) a função que mede o desempenho do modelo apresenta, ao fim de 100 épocas de treinamento, valores de perda (loss) menores quando aplicada ao segundo modelo, com respeito aos dados de treinamento e validação\n",
        "#       b) a loss function utilizada no segundo modelo não é a mesma utilizada no primeiro, dados os comportamentos distintos nos dois modelos (no primeiro, irregular e com picos que distanciam os valores referentes ao treinamento e à validação;\n",
        "#                                                                                                                                               no segundo, minimização estável dos valores de perda e simultânea diminuição destes valores em ambos os processos)\n",
        "#\n",
        "#    Uma medida a se tomar contra o desempenho insatisfatório do primeiro modelo seria a aplicação de outra loss function nos processos de treinamento e validação"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddyIOU9A2Pwg",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "# Dados e enunciado para questão 5, 6 e 7:\n",
        "\n",
        "***   \n",
        "## Context\n",
        "This is the dataset used in the second chapter of Aurélien Géron's recent book 'Hands-On Machine learning with Scikit-Learn and TensorFlow'. It serves as an excellent introduction to implementing machine learning algorithms because it requires rudimentary data cleaning, has an easily understandable list of variables and sits at an optimal size between being to toyish and too cumbersome.\n",
        "\n",
        "The data contains information from the 1990 California census. So although it may not help you with predicting current housing prices like the Zillow Zestimate dataset, it does provide an accessible introductory dataset for teaching people about the basics of machine learning.\n",
        "\n",
        "*datapath: https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.csv*\n",
        "***\n",
        "\n",
        "### Questão 5: Organização dos dados\n",
        "\n",
        "**a)** Através de uma biblioteca, receba os dados e explore-os  \n",
        "**b)** Plote gráficos que descrevam como se comportam as distribuições das colunas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaHMb6I42Pwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# R:\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "datapath = 'https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.csv'\n",
        "data = pd.read_csv(datapath)\n",
        "\n",
        "for item in data.columns:\n",
        "    plt.hist(data[item], bins=100)\n",
        "    plt.suptitle(item)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpLcfdKI2Pwm",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### Questão 6: Feature Engineering e lidando com dados categorizados\n",
        "\n",
        "**a)** Crie uma nova coluna a partir de uma ou mais colunas  \n",
        "**b)** Encontre uma forma de representar os dados categóricos em forma numérica\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnApO82t2Pwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# R: Criaremos a coluna relative_capacity, obtida a partir da divisão elemento a elemento entre as colunas total_bedrooms e total_rooms, isto é, total_bedrooms/total_rooms;\n",
        "#   \n",
        "#    Representaremos numericamente os rótulos da coluna ocean_proximity. Visto que esta pode ser quantizada, podemos ordenar os rótulos do mais distante do mar ao mais próximo,\n",
        "#    obtendo: inland > (<1h ocean) > near bay > near ocean > island, podemos então atribuir os respectivos valores: 5,4,3,2,1\n",
        "\n",
        "relative_capacity = list(data.total_bedrooms/data.total_rooms)\n",
        "plt.hist(relative_capacity, bins=1500)\n",
        "plt.suptitle('relative_capacity')\n",
        "plt.show()\n",
        "\n",
        "num_ocean_proximity = list()\n",
        "for row in data.ocean_proximity:\n",
        "    if(row==\"INLAND\"):\n",
        "        num_ocean_proximity.append(5)\n",
        "    if(row==\"<1H OCEAN\"):\n",
        "        num_ocean_proximity.append(4)\n",
        "    if(row==\"NEAR BAY\"):\n",
        "        num_ocean_proximity.append(3)\n",
        "    if(row==\"NEAR OCEAN\"):\n",
        "        num_ocean_proximity.append(2)\n",
        "    if(row==\"ISLAND\"):\n",
        "        num_ocean_proximity.append(1)\n",
        "plt.hist(num_ocean_proximity, bins=10)\n",
        "plt.suptitle(\"Numerical Ocean Proximity\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhA1bKDm2Pwt",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### Questão 7: Classificação\n",
        "\n",
        "**a)** Prepare os dados para classificar de acordo com o preço, dividido em três classes (barato, médio e caro)  \n",
        "**b)** Faça um modelo para classificar os dados  \n",
        "**c)** Avalie o seu modelo  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8JaMFUy2Pwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# R: Pela natureza dos dados, será utilizado o algoritmo de K-Nearest Neighbors.\n",
        "#    Para que o modelo funcione como um classificador autêntico, é preciso padronizar os dados da coluna median_house_value em três categorias, a saber, barato, mediano e caro.\n",
        "#    Construída a nova coluna, é preciso dividir as observações entre o treinamento e a validação.\n",
        "#    Feito isso, o modelo se utilizará destes três labels para se adaptar aos dados de treinamento, e, por fim, será avaliado por observações que não foram anteriormente apresentadas.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# a)\n",
        "# Cria a nova coluna, substituindo preços por categorias\n",
        "boundaries = [200000, 400000, 600000]\n",
        "labels = [\"BARATO\", \"MEDIANO\", \"CARO\"]\n",
        "classified_values = []\n",
        "for price in data.median_house_value:\n",
        "    for i in range(3):\n",
        "        if (price < boundaries[i]):\n",
        "            classified_values.append(labels[i])\n",
        "            break\n",
        "\n",
        "# Data Preprocessing\n",
        "data[\"NUM_ocean_proximity\"] = num_ocean_proximity # adiciona a coluna de distâncias numéricas do oceano\n",
        "feature_names = ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'NUM_ocean_proximity']\n",
        "\n",
        "## Corrige os valores NaN\n",
        "filtered_data = data.fillna(method='ffill')\n",
        "\n",
        "X, y = filtered_data[feature_names], pd.DataFrame(classified_values, columns=[\"CATEGORIES\"])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) # Separa o dataset entre dados de treinamento e dados de validação\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)\n",
        "\n",
        "# b)\n",
        "# Treinamento do modelo\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# c)\n",
        "# Avaliação do modelo\n",
        "print(\"Acurácia nos dados de treinamento: {:.4f}\".format(knn.score(X_train, y_train)))\n",
        "print(\"Acurácia nos dados de validação: {:.4f}\".format(knn.score(X_test, y_test)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RktYcEw32Pwy",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### Questão 8:  PCA\n",
        "##### Descreva de maneira suscinta e objetiva o funcionamento do algorítmo PCA e suas utilidades"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8UiPiEn2Pwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# R: Principal Component Analysis é uma técnica de redução dimensional. Em Data Science é utilizada principalmente para diminuir o número de variáveis em um dataset, facilitando assim a visualização e análise desses dados. \n",
        "#    A particularidade do PCA é que, apesar da redução nos dados, a maior parte da informação continua presente no dataset resultante, ou seja: redução de dados com pouca perda de informação valiosa."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX6lFSyA2Pw4",
        "colab_type": "text"
      },
      "source": [
        "### Questão 9: Equações de Bellman\n",
        "##### Explique com suas palavras de maneira detalhada as equações de Bellman.\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVhJ9sse2Pw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# R: A Equação de Bellman expressa o valor de um determinado estado como o somatório de recompensas de um estado terminal, com as recompensas de cada ação descontadas termo a termo."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxMMohkX2PxC",
        "colab_type": "text"
      },
      "source": [
        "### Questão 10: Attention Model\n",
        "\n",
        "###### Explique com suas palavras o funcionamento de um Attention Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yrdSWve2PxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# R: Attention Model é uma técnica que replica a metodologia de resolução de problemas \"dividir e conquistar\" no mecanismo de aquisição de entradas de um modelo de Deep Learning, isto é, um attention model faz o modelo\n",
        "#    focar em determinados aspectos dos dados de entrada sequencialmente, procurando resolver problemas menores individualmente."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}